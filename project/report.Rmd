---
title: "Report: Source Code for Simluations and Figure"
author: "Junfan Huang and Daniel Jones"
date: "10/12/2018"
output:
  pdf_document:
    toc: false
    df_print: kable
    latex_engine: xelatex
geometry: margin=2cm
documentclass: amsart
monofont: "Source Code Pro"
---

Load in any libraries we need, and the data. Running `R --file install.R` should install any missing dependencies.

```{r setup}
library(caret)
library(data.table)
library(e1071)
library(ggplot2)
library(ranger)
library(knitr)
library(rpart)
library(parallel)
library(magrittr)
library(dplyr)
library(BBmisc)
library(Rtsne)
library(ROSE)

set.seed(0xC0FFEE)

knitr::opts_knit$set(root.dir='../')
knitr::opts_chunk$set(echo=TRUE)
```

```{r load_data_set}
columns <- read.table(
    "./data/kddcup.names",
    sep=":",
    skip=1,  # the first column name are the labels, but those are at the end!
    as.is=T
)
column_names <- c(columns[,1], 'label')

connection_events <- read.csv(
    "./data/kddcup.data_10_percent.gz",
    col.names=column_names
)

setDT(connection_events)  # convert from data.frame to data.table
```

Set up a common set of k-folds for model validation.
```{r eval=FALSE}
k_folds <- createFolds(connection_events$label, k=10)
```

```{r include=FALSE, eval=FALSE}
saveRDS(k_folds, file='./data/k-folds.rds')
```

```{r include=FALSE, eval=TRUE}
k_folds <- readRDS(file='./data/k-folds.rds')
```

This generates 10 sets of indices on the data. These are arranged such that similar amounts of each label are in each set.

To use them for k-fold cross-validation:

  1. Pick each fold one at a time.
  2. Treat this as the indices of the testing set.
  3. Select all other connection events as the training set.
  4. Train your model and get your predictions from the test set.

We've defined some utility functions to help keep our work consistent:
```{r}
# Define a function for this to make sure all of our confusion matrices use
# consistent labelling and axis' for true/predicted classes.
make_confusion_matrix <- function(true_values, predicted_values) {
    table(predicted_values, true_values)
}

# Define a function to plot a confusion matrix with a logarithm axis (well,
# log(x+1) to ensure 0 maps to 0). Expects the format output by the
# make_confusion_matrix function above.
plot_log_confusion_matrix <- function(confusion_matrix) {
    breaks <- c(0, 1, 10, 100, 1000, 10000) * max(confusion_matrix) / 10000
    labels <- sapply(breaks, function(break_value) sprintf("%.0f", break_value))

    confusion_matrix <- as.data.table(confusion_matrix)
    colnames(confusion_matrix) <- c('Predicted', 'True', 'Frequency')

    plot <- ggplot(
            data=confusion_matrix,
            aes(x=Predicted, y=True, fill=Frequency),
            limits=c(0, max(confusion_matrix))
    ) +
        geom_raster() +
        theme(axis.text.x=element_text(angle=90, hjust=1)) +
        scale_fill_gradient(name="Frequency", trans = "log1p", breaks=breaks, labels=labels)

   return(plot)
}

# Define a function to plot a confusion matrix. Expects the format output by the
# make_confusion_matrix function above.
plot_confusion_matrix <- function(confusion_matrix) {
    confusion_matrix <- as.data.table(confusion_matrix)
    colnames(confusion_matrix) <- c('Predicted', 'True', 'Frequency')

    plot <- ggplot(
            data=confusion_matrix,
            aes(x=Predicted, y=True, fill=Frequency),
            limits=c(0, max(confusion_matrix))
    ) +
        geom_raster() +
        theme(axis.text.x=element_text(angle=90, hjust=1)) +
        scale_fill_gradient(name="Frequency")

   return(plot)
}


ModelResults <- function(data_transformation_function, k_folds, fold_predictions) {
    ## "Class" to save the results from a model test. Takes:
    ##
    ##   data_transformation_function: function which takes in
    ##      the kdd-99 data and returns a data set ready for
    ##      the model.
    ##
    ##   k_folds: a list of "folds", each of which is a list of
    ##     indices pointing to the rows in the data set which
    ##     should be left out.
    ##
    ##   predictions: the results of running the model against
    ##      the testing set of each fold.

    self <- list()

    self$transform_function <- data_transformation_function
    self$folds <- k_folds
    self$predictions <- fold_predictions

    self$transformed_data <- function(data) {
        return(self$transform_function(data))
    }

    self$confusion_matrix <- function(data) {
        transformed_data <- self$transformed_data(data)
        testing_labels <- lapply(self$folds, function(fold) transformed_data[fold]$label)

        confusion_matrices <- mapply(
            make_confusion_matrix,
            testing_labels,
            self$predictions,
            SIMPLIFY=FALSE
        )

        summary_matrix <- Reduce('+', confusion_matrices)

        return(summary_matrix)
    }

    self$plot_confusion_matrix <- function(data, log=FALSE) {
        confusion_matrix <- self$confusion_matrix(data)

        if (log==TRUE) {
            plot_log_confusion_matrix(confusion_matrix)
        } else {
            plot_confusion_matrix(confusion_matrix)
        }
    }

    return(self)
}

plot_frequency_table <- function(freq_table) {
    colnames(freq_table) <- c('Predicted', 'True', 'Frequency')

    all_classes <- union(freq_table$Predicted, freq_table$True)

    plot <- ggplot(data=freq_table) +
        lims(fill=c(0, max(freq_table$Frequency))) +
        aes(x=Predicted, y=True, fill=Frequency) +
        geom_raster() +
        theme(axis.text.x=element_text(angle=90, hjust=1))

    return(plot)
}

# Makes a nice table listing all the classification errors in a confusion
# matrix (and their frequency):
get_classification_errors <- function(confusion_matrix) {
    confusion_table <- as.data.table(confusion_matrix)
    colnames(confusion_table) <- c('Predicted', 'True', 'Frequency')
    confusion_table[Predicted!=True & Frequency > 0][order(-Frequency)]
}
```

The following function takes in the list of folds, and a corresponding list of predictions from a model. It will add these predictions as a column to the data frame using the indexes contained in the fold variable:
```{r}
add_predictions <- function(data, folds, predictions, new_column_name) {
    combined_indices <- Reduce(append, folds)
    combined_predictions <- Reduce(append, predictions)

    combined_predictions <- as.factor(combined_predictions)
    levels(combined_predictions) <- levels(predictions[[1]])

    predictions_by_index <- data.table(
        index=combined_indices,
        prediction=combined_predictions
    )

    correctly_ordered_predictions <- predictions_by_index[order(index)]$prediction

    new_data <- copy(data)
    new_data[[new_column_name]] <- correctly_ordered_predictions

    levels(new_data[[new_column_name]]) <- levels(correctly_ordered_predictions)

    return(new_data)
}
```


The taffic labels are grouped by attack type, here we load this mapping in and generate the `attack_categories` data table:
```{r}
attack_categories <- fread(
    './data/training_attack_types',
    col.names=c('attack', 'category'),
    header=FALSE
)
# Make these attack names consistent with the main data set
attack_categories$attack <- sapply(
    attack_categories$attack,
    function(name) paste(name, '.', sep='')
)
attack_categories$category <- sapply(
    attack_categories$category,
    function(name) paste(name, '.', sep='')
)
# `normal` isn't really an attack, but add it as it's own
# category
attack_categories <- rbind(
    attack_categories,
    list('normal.', 'normal.')
)
```


Each of the headings below represents a model, and the code used to generate it's figures. In general, if a model takes a long time to run, we've saved the results, and a code snippet below shows how to load in those results (and skip running the model yourself).


# Decision Tree

# Weighted Decision Tree

# K-Means
## Finding 5 Clusters by Attack Categories
## Finding 20 Clusters by Attack Type

(normalization part)

# Embedding 5 cluster k-means in a Decision Tree

# Embedding 2 cluster k-means in a Decision Tree

# Random Forest

# Undersamping
## 23 labels
### Simple Sampling
### K-Means
## 4 labels
### Simple Sampling
### K-Means

# Oversampling
### Add data from whole data
### Create data by SMOTE

# Visualization
### DOS attacks
### Decision Tree
### Random forest
